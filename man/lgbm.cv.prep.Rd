% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lgbm.cv.prep.R
\name{lgbm.cv.prep}
\alias{lgbm.cv.prep}
\title{LightGBM Cross-Validated Model Preparation}
\usage{
lgbm.cv.prep(y_train, x_train, x_test = NA, SVMLight = FALSE,
  data_has_label = FALSE, NA_value = "nan", workingdir = getwd(),
  train_name = "lgbm_train.csv", val_name = "lgbm_val.csv",
  test_name = "lgbm_test.csv", verbose = TRUE, folds = 5,
  folds_weight = NA, stratified = TRUE, fold_seed = 0,
  fold_cleaning = 50)
}
\arguments{
\item{y_train}{Type: vector. The training labels.}

\item{x_train}{Type: data.table. The training features.}

\item{x_test}{Type: data.table. The testing features, if necessary. Not providing a data.frame or a matrix results in at least 3x memory usage. Defaults to \code{NA}.}

\item{SVMLight}{Type: boolean. Whether the input is a dgCMatrix to be output to SVMLight format. Setting this to \code{TRUE} enforces you must provide labels separately (in \code{y_train}) and headers will be ignored. This is default behavior of SVMLight format. Defaults to \code{FALSE}.}

\item{data_has_label}{Type: boolean. Whether the data has labels or not. Do not modify this. Defaults to \code{FALSE}.}

\item{NA_value}{Type: numeric or character. What value replaces NAs. Use \code{"na"} if you want to specify "missing". It is not recommended to use something else, even by soemthing like a numeric value out of bounds (like \code{-999} if all your values are greater than \code{-999}). You should change from the default \code{"na"} if they have a real numeric meaning. Defaults to \code{"na"}.}

\item{workingdir}{Type: character. The working directory used for LightGBM. Defaults to \code{getwd()}.}

\item{train_name}{Type: character. The name of the default training data file for the model. Defaults to \code{'lgbm_train.csv'}.}

\item{val_name}{Type: character. The name of the default validation data file for the model. Defaults to \code{'lgbm_val.csv'}.}

\item{test_name}{Type: character. The name of the testing data file for the model. Defaults to \code{'lgbm_test.csv'}.}

\item{verbose}{Type: boolean. Whether \code{fwrite} data is output. Defaults to \code{TRUE}.}

\item{folds}{Type: integer, vector of two integers, vector of integers, or list. If a integer is supplied, performs a \code{folds}-fold cross-validation. If a vector of two integers is supplied, performs a \code{folds[1]}-fold cross-validation repeated \code{folds[2]} times. If a vector of integers (larger than 2) was provided, each integer value should refer to the fold, of the same length of the training data. Otherwise (if a list was provided), each element of the list must refer to a fold and they will be treated sequentially. Defaults to \code{5}.}

\item{folds_weight}{Type: vector of numerics. The weights assigned to each fold. If no weight is supplied (\code{NA}), the weights are automatically set to \code{rep(1/length(folds))} for an average (does not mix well with folds with different sizes). When the folds are automatically created by supplying \code{fold} a vector of two integers, then the weights are automatically computed. Defaults to \code{NA}.}

\item{stratified}{Type: boolean. Whether the folds should be stratified (keep the same label proportions) or not. Defaults to \code{TRUE}.}

\item{fold_seed}{Type: integer or vector of integers. The seed for the random number generator. If a vector of integer is provided, its length should be at least longer than \code{n}. Otherwise (if an integer is supplied), it starts each fold with the provided seed, and adds 1 to the seed for every repeat. Defaults to \code{0}.}

\item{fold_cleaning}{Type: integer. When using cross-validation, data must be subsampled. This parameter controls how aggressive RAM usage should be against speed. The lower this value, the more aggressive the method to keep memory usage as low as possible. Defaults to \code{50}.}
}
\value{
The \code{folds} and \code{folds_weight} elements in a list. All files are output and ready to use for \code{lgbm.cv} with \code{files_exist = TRUE}.
}
\description{
This function allows you to prepare the cross-validatation of a LightGBM model.
It is recommended to have your x_train and x_val sets as data.table (or data.frame), and the data.table development version. To install data.table development version, please run in your R console: \code{install.packages("data.table", type = "source", repos = "http://Rdatatable.github.io/data.table")}.
SVMLight conversion requires Laurae's sparsity package, which can be installed using \code{devtools:::install_github("Laurae2/sparsity")}.
Does not handle weights or groups.
}
\examples{
\dontrun{
Prepare files for cross-validation.
trained.cv <- lgbm.cv(y_train = targets,
                      x_train = data[1:1500, ],
                      workingdir = file.path(getwd(), "temp"),
                      train_conf = 'lgbm_train.conf',
                      train_name = 'lgbm_train.csv',
                      val_name = 'lgbm_val.csv',
                      folds = 3)
}

}

