% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LossFunctions.R
\name{loss_Poisson_xgb}
\alias{loss_Poisson_xgb}
\title{Laurae's Poisson Error (xgboost function)}
\usage{
loss_Poisson_xgb(preds, dtrain)
}
\arguments{
\item{preds}{The \code{predictions}.}

\item{dtrain}{The xgboost model.}
}
\value{
The gradient and the hessian of the Laurae's Poisson Error per value in a list.
}
\description{
This function computes for xgboost's \code{obj} function the Laurae's Poisson Error loss gradient and hessian per value provided \code{preds} and \code{dtrain}. Negative and null values are set to \code{1e-15}.
}
\details{
This loss function is strictly positive, therefore defined in \code{\]0, +Inf\[}. It penalizes lower values more heavily, and as such is a good fit for typical problems requiring fine tuning when undercommitting on the predictions. The negative values are cancelled out to make the loss function positive, with \code{loss = 0} when \code{y_true = y_pred}. This loss function is experimental.

Loss Formula : \eqn{(y_pred - y_true * log(y_pred))}

Gradient Formula : \eqn{1 - y_true/y_pred}

Hessian Formula : \eqn{y_true/(y_pred * y_pred)}
}

