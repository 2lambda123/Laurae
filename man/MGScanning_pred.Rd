% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MGScanning_pred.R
\name{MGScanning_pred}
\alias{MGScanning_pred}
\title{Multi-Grained Scanning Predictor implementation in R}
\usage{
MGScanning_pred(model, data, dimensions = NULL, multi_class = NULL,
  data_start = NULL)
}
\arguments{
\item{model}{Type: list. A model trained by \code{MGScanning}.}

\item{data}{Type: data.table. A data to predict on. If passing training data, it will predict as if it was out of fold and you will overfit (so, use the list \code{preds} instead please).}

\item{dimensions}{Type: numeric. The dimensions of the data. Only supported is \code{1} for matrix format, and \code{2} for list of matrices. Defaults to \code{NULL}.}

\item{multi_class}{Type: numeric. How many classes you got. Set to 2 for binary classification, or regression cases. Set to \code{NULL} to let it try guessing by reading the \code{model}. Defaults to \code{NULL}.}

\item{data_start}{Type: vector of numeric. The initial prediction labels. Set to \code{NULL} if you do not know what you are doing. Defaults to \code{NULL}.}
}
\value{
A data.table or a list based on \code{data} predicted using \code{model}.
}
\description{
This function attempts to predict from Multi-Grained Scanning using xgboost.
}
\details{
For implementation details of Cascade Forest / Complete-Random Tree Forest / Multi-Grained Scanning / Deep Forest, check this: \url{https://github.com/Microsoft/LightGBM/issues/331#issuecomment-283942390} by Laurae.
}
\examples{
\dontrun{
# Load libraries
library(data.table)
library(Matrix)
library(xgboost)

# Create data
data(agaricus.train, package = "lightgbm")
data(agaricus.test, package = "lightgbm")
agaricus_data_train <- data.table(as.matrix(agaricus.train$data))
agaricus_data_test <- data.table(as.matrix(agaricus.test$data))
agaricus_label_train <- agaricus.train$label
agaricus_label_test <- agaricus.test$label
folds <- Laurae::kfold(agaricus_label_train, 5)

# Train a model (binary classification)
model <- MGScanning(data = agaricus_data_train, # Training data
                    labels = agaricus_label_train, # Training labels
                    folds = folds, # Folds for cross-validation
                    dimensions = 1, # Change this for 2 dimensions if needed
                    depth = 10, # Change this to change the sliding window size
                    stride = 1, # Change this to change the sliding window speed
                    nthread = 1, # Change this to use more threads
                    lr = 1, # Do not touch this unless you are expert
                    training_start = NULL, # Do not touch this unless you are expert
                    validation_start = NULL, # Do not touch this unless you are expert
                    n_forest = 2, # Number of forest models
                    n_trees = 30, # Number of trees per forest
                    random_forest = 1, # We want only 2 random forest
                    seed = 0,
                    objective = "binary:logistic",
                    eval_metric = "logloss",
                    multi_class = 2, # Modify this for multiclass problems)
                    verbose = TRUE)

# Create predictions
data_predictions <- model$preds

# Make real predictions
new_preds <- MGScanning_pred(model, data = agaricus_data_test)

# Example on fake pictures (matrices) and multiclass problem

# Generate fake images
new_data <- list(matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20))

# Generate fake labels
new_labels <- c(2, 1, 0, 2, 1, 0, 2, 1, 0, 0)

# Train a model (multiclass problem)
model <- MGScanning(data = new_data, # Training data
                    labels = new_labels, # Training labels
                    folds = list(1:3, 3:6, 7:10), # Folds for cross-validation
                    dimensions = 2,
                    depth = 10,
                    stride = 1,
                    nthread = 1, # Change this to use more threads
                    lr = 1, # Do not touch this unless you are expert
                    training_start = NULL, # Do not touch this unless you are expert
                    validation_start = NULL, # Do not touch this unless you are expert
                    n_forest = 2, # Number of forest models
                    n_trees = 10, # Number of trees per forest
                    random_forest = 1, # We want only 2 random forest
                    seed = 0,
                    objective = "multi:softprob",
                    eval_metric = "mlogloss",
                    multi_class = 3, # Modify this for multiclass problems)
                    verbose = TRUE)

# Matrix output is 10x600
dim(model$preds)

# Real predictions on new data
new_data <- list(matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20),
                 matrix(rnorm(n = 400), ncol = 20, nrow = 20))
new_preds <- MGScanning_pred(model, data = new_data)
}

}

